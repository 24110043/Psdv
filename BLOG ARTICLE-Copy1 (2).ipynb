{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c32a899-4896-4371-a2a6-f0d6abe7748a",
   "metadata": {},
   "source": [
    "**SKRUB** :  A Python library for cleaning, structuring, and visualizing tabular data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df34b56-ac20-4dac-8778-d15e1d9c5279",
   "metadata": {},
   "source": [
    "**INTRODUCTION**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3cf2735-3f23-474f-9bb2-d07896e54d93",
   "metadata": {},
   "source": [
    "How to deal with messy data Missing values, inconsistent formats, and unstructured information slow down data analysis? here skrub comes in picture!\n",
    "skrub is a powerful Python library designed to clean, structure, and prepare tabular data efficiently. In this guide, we’ll explore its key features\n",
    "\n",
    "skrub makes cleaning, organizing, and visualizing messy tables easier and faster\n",
    "\n",
    " **Data Cleaning** – Removes inconsistencies, trims spaces, and fixes column names.\n",
    " \n",
    " **Handling Missing Data** – Easily fills missing values.\n",
    " \n",
    " **Dataset Merging**– Intelligently links datasets, even with slight variations.\n",
    " \n",
    " **Quick Insights**– Generates structured data for visualization & analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0d81ec-f4fa-4470-93d5-2a7c58a75bf0",
   "metadata": {},
   "source": [
    "**WHY SKRUB?**\n",
    "\n",
    "**Assembling Tables with Precision**:Skrub excels at joining tables on keys of different types, including string, numerical, and datetime, with an impressive ability to handle imprecise correspondences.\n",
    "\n",
    "**Fuzzy Joining for Seamless Integration**: selects the type of fuzzy matching based on column types, producing a similarity score for easy identification of less-than-perfect matches\n",
    "\n",
    "**Advanced Analysis Made Simple**:Skrub takes table joining to the next level with features like Joiner, AggJoiner, and AggTarget.\n",
    "\n",
    "**Efficient Column Selection in Pipelines**:Apart from joins, skrub also facilitates column selection within a pipeline, allowing data scientists to choose and discard columns dynamically.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc052c6-b637-4102-8c8f-5c7cfed7eb6d",
   "metadata": {},
   "source": [
    "**INSTALLATION PROCESS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5d262cf-e2f1-4b1d-a3e6-bf9334722ca2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: skrub in c:\\users\\nihar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.5.1)\n",
      "Requirement already satisfied: numpy>=1.23.5 in c:\\users\\nihar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from skrub) (2.2.1)\n",
      "Requirement already satisfied: packaging>=23.1 in c:\\users\\nihar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from skrub) (24.2)\n",
      "Requirement already satisfied: pandas>=1.5.3 in c:\\users\\nihar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from skrub) (2.2.3)\n",
      "Requirement already satisfied: scikit-learn>=1.2.1 in c:\\users\\nihar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from skrub) (1.6.1)\n",
      "Requirement already satisfied: scipy>=1.9.3 in c:\\users\\nihar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from skrub) (1.15.2)\n",
      "Requirement already satisfied: jinja2>=3.1.2 in c:\\users\\nihar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from skrub) (3.1.5)\n",
      "Requirement already satisfied: matplotlib>=3.4.3 in c:\\users\\nihar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from skrub) (3.10.0)\n",
      "Requirement already satisfied: requests>=2.25.0 in c:\\users\\nihar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from skrub) (2.32.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\nihar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2>=3.1.2->skrub) (3.0.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\nihar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.4.3->skrub) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\nihar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.4.3->skrub) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\nihar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.4.3->skrub) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\nihar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.4.3->skrub) (1.4.8)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\nihar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.4.3->skrub) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\nihar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.4.3->skrub) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\nihar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.4.3->skrub) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\nihar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas>=1.5.3->skrub) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\nihar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas>=1.5.3->skrub) (2025.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\nihar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.25.0->skrub) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\nihar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.25.0->skrub) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\nihar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.25.0->skrub) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nihar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.25.0->skrub) (2025.1.31)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\nihar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn>=1.2.1->skrub) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\nihar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn>=1.2.1->skrub) (3.5.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\nihar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.4.3->skrub) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install skrub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "566c3270-3b6b-4ee7-ae44-cb8393051c85",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: skrub in c:\\users\\nihar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.5.1)\n",
      "Requirement already satisfied: numpy>=1.23.5 in c:\\users\\nihar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from skrub) (2.2.1)\n",
      "Requirement already satisfied: packaging>=23.1 in c:\\users\\nihar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from skrub) (24.2)\n",
      "Requirement already satisfied: pandas>=1.5.3 in c:\\users\\nihar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from skrub) (2.2.3)\n",
      "Requirement already satisfied: scikit-learn>=1.2.1 in c:\\users\\nihar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from skrub) (1.6.1)\n",
      "Requirement already satisfied: scipy>=1.9.3 in c:\\users\\nihar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from skrub) (1.15.2)\n",
      "Requirement already satisfied: jinja2>=3.1.2 in c:\\users\\nihar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from skrub) (3.1.5)\n",
      "Requirement already satisfied: matplotlib>=3.4.3 in c:\\users\\nihar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from skrub) (3.10.0)\n",
      "Requirement already satisfied: requests>=2.25.0 in c:\\users\\nihar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from skrub) (2.32.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\nihar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2>=3.1.2->skrub) (3.0.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\nihar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.4.3->skrub) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\nihar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.4.3->skrub) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\nihar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.4.3->skrub) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\nihar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.4.3->skrub) (1.4.8)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\nihar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.4.3->skrub) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\nihar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.4.3->skrub) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\nihar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib>=3.4.3->skrub) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\nihar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas>=1.5.3->skrub) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\nihar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas>=1.5.3->skrub) (2025.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\nihar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.25.0->skrub) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\nihar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.25.0->skrub) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\nihar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.25.0->skrub) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nihar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.25.0->skrub) (2025.1.31)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\nihar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn>=1.2.1->skrub) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\nihar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn>=1.2.1->skrub) (3.5.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\nihar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.4.3->skrub) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade skrub\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8581911a-e19a-472c-91f6-e15b5921378f",
   "metadata": {},
   "source": [
    "**USING SKRUB**\n",
    "\n",
    "**1.HANDLING MISSING DATAFILES:**\n",
    "\n",
    "We always find issues when cleaning data is dealing with missing or NaN values. With Skrub, you can fill or drop these missing values with just a few lines of code.\n",
    "\n",
    "for example consider this code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5340ea90-7074-4a9a-a03b-98d4031e3453",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>City</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alice</td>\n",
       "      <td>25.0</td>\n",
       "      <td>New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bob</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Paris</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>22.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Eve</td>\n",
       "      <td>29.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Name   Age      City\n",
       "0  Alice  25.0  New York\n",
       "1    Bob   NaN     Paris\n",
       "2   None  22.0      None\n",
       "3    Eve  29.0      None"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#filling missing values\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "data = {\n",
    "    'Name': ['Alice', 'Bob', None, 'Eve'],\n",
    "    'Age': [25, None, 22, 29],\n",
    "    'City': ['New York', 'Paris', None, None]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acccb283-99ba-45e4-980e-6d85bc1da4b9",
   "metadata": {},
   "source": [
    "we can use skrub’s missing module to fill the missing values. For example, to fill numerical columns with the mean and categorical columns with the mode, we can use th following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10875f00-cffc-4c81-a6a6-009965ab2197",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data:\n",
      "    Name   Age      City\n",
      "0  Alice  25.0  New York\n",
      "1    Bob   NaN     Paris\n",
      "2   None  22.0      None\n",
      "3    Eve  29.0      None\n",
      "\n",
      "Data After Filling Missing Values:\n",
      "      Name        Age      City\n",
      "0    Alice  25.000000  New York\n",
      "1      Bob  25.333333     Paris\n",
      "2  Unknown  22.000000   Unknown\n",
      "3      Eve  29.000000   Unknown\n",
      "\n",
      "Data After Standardizing 'Age' Column:\n",
      "      Name       Age      City\n",
      "0    Alice -0.134231  New York\n",
      "1      Bob  0.000000     Paris\n",
      "2  Unknown -1.342312   Unknown\n",
      "3      Eve  1.476543   Unknown\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from skrub import TableVectorizer  # Correct import\n",
    "\n",
    "# Sample data with missing values\n",
    "data = {\n",
    "    'Name': ['Alice', 'Bob', None, 'Eve'],\n",
    "    'Age': [25, None, 22, 29],\n",
    "    'City': ['New York', 'Paris', None, None]\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(\"Original Data:\")\n",
    "print(df)\n",
    "\n",
    "# Fill missing values correctly (avoid FutureWarning)\n",
    "df['Age'] = df['Age'].fillna(df['Age'].mean())  # Filling missing Age with the mean\n",
    "df['Name'] = df['Name'].fillna('Unknown')\n",
    "df['City'] = df['City'].fillna('Unknown')\n",
    "\n",
    "print(\"\\nData After Filling Missing Values:\")\n",
    "print(df)\n",
    "\n",
    "# Standardize the 'Age' column\n",
    "scaler = StandardScaler()\n",
    "df['Age'] = scaler.fit_transform(df[['Age']])\n",
    "\n",
    "print(\"\\nData After Standardizing 'Age' Column:\")\n",
    "print(df)\n",
    "\n",
    "# Vectorize the table (convert categorical data into numerical featur\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e8570f-b099-4a3c-8186-c564501f2cd8",
   "metadata": {},
   "source": [
    " The age column is replaced with its mean value.\n",
    " \n",
    "the missing Name and City values are replaced with the string 'Unknown'. \n",
    "\n",
    "TableVectorizer handles the categorical features and converts them into binary features (one-hot encoding).\n",
    "Output\n",
    "The cleaned data is now numerical, and we can see how missing values were handled."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94228f0b-9581-48c0-bdd3-4d3972202f70",
   "metadata": {},
   "source": [
    "**2.STANDARDIZING DATA**\n",
    "\n",
    "  skrub can be useful standardize numerical data, by making sure that values are consistent across the dataset. \n",
    "For example, if we have a column of Age values with a large range, we can scale it between 0 and 1 using normalization or standardization techniques.\n",
    "\n",
    "for example analyze the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc63805b-6ff7-4557-b971-f6021e6a5f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data:\n",
      "    Name   Age      City\n",
      "0  Alice  25.0  New York\n",
      "1    Bob   NaN     Paris\n",
      "2   None  22.0      None\n",
      "3    Eve  29.0      None\n",
      "\n",
      "Data After Filling Missing Values:\n",
      "      Name        Age      City\n",
      "0    Alice  25.000000  New York\n",
      "1      Bob  25.333333     Paris\n",
      "2  Unknown  22.000000   Unknown\n",
      "3      Eve  29.000000   Unknown\n",
      "\n",
      "Data After Standardizing 'Age' Column:\n",
      "      Name       Age      City\n",
      "0    Alice -0.134231  New York\n",
      "1      Bob  0.000000     Paris\n",
      "2  Unknown -1.342312   Unknown\n",
      "3      Eve  1.476543   Unknown\n",
      "\n",
      "Vectorized Data:\n",
      "   Name_Alice  Name_Bob  Name_Eve  Name_Unknown       Age  City_New York  \\\n",
      "0         1.0       0.0       0.0           0.0 -0.134231            1.0   \n",
      "1         0.0       1.0       0.0           0.0  0.000000            0.0   \n",
      "2         0.0       0.0       0.0           1.0 -1.342312            0.0   \n",
      "3         0.0       0.0       1.0           0.0  1.476543            0.0   \n",
      "\n",
      "   City_Paris  City_Unknown  \n",
      "0         0.0           0.0  \n",
      "1         1.0           0.0  \n",
      "2         0.0           1.0  \n",
      "3         0.0           1.0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from skrub._table_vectorizer import TableVectorizer\n",
    "\n",
    "# Sample data with missing values\n",
    "data = {\n",
    "    'Name': ['Alice', 'Bob', None, 'Eve'],\n",
    "    'Age': [25, None, 22, 29],\n",
    "    'City': ['New York', 'Paris', None, None]\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(\"Original Data:\")\n",
    "print(df)\n",
    "\n",
    "# Fill missing values correctly (avoid FutureWarning)\n",
    "df['Age'] = df['Age'].fillna(df['Age'].mean())  # Filling missing Age with the mean\n",
    "df['Name'] = df['Name'].fillna('Unknown')\n",
    "df['City'] = df['City'].fillna('Unknown')\n",
    "\n",
    "print(\"\\nData After Filling Missing Values:\")\n",
    "print(df)\n",
    "\n",
    "# Standardize the 'Age' column\n",
    "scaler = StandardScaler()\n",
    "df['Age'] = scaler.fit_transform(df[['Age']])\n",
    "\n",
    "print(\"\\nData After Standardizing 'Age' Column:\")\n",
    "print(df)\n",
    "\n",
    "# Vectorize the table (convert categorical data into numerical features)\n",
    "vectorizer = TableVectorizer()\n",
    "df_vectorized = vectorizer.fit_transform(df)\n",
    "\n",
    "print(\"\\nVectorized Data:\")\n",
    "print(df_vectorized)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab99db1-e022-4e32-aa0e-ee90aa418e4f",
   "metadata": {},
   "source": [
    "\n",
    "The code fills missing values in the Age, Name, and City columns, then standardizes the Age column using StandardScaler. Afterward, it uses TableVectorizer to convert the entire dataframe into numerical features for machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43bd61b1-fc28-43e7-8b80-05d8d8da2608",
   "metadata": {},
   "source": [
    "**3.TRANSFORMING CATEGEORICAL VARIABLES:**\n",
    "\n",
    "Categorical variables, such as names of cities or product categories, must be encoded into numerical values to be applied it  machine learning algorithms. \n",
    "\n",
    "Skrub makes this easy with the TableVectorizer, which handles one-hot encoding and other encoding methods automatically.\n",
    "\n",
    "oberse the code below.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5969ed34-51f4-4522-9b99-70d99063e070",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Transformed Data (Categorical Encoded):\n",
      "   Name_Alice  Name_Bob  Name_Eve  Name_Unknown       Age  City_New York  \\\n",
      "0         1.0       0.0       0.0           0.0 -0.134231            1.0   \n",
      "1         0.0       1.0       0.0           0.0  0.000000            0.0   \n",
      "2         0.0       0.0       0.0           1.0 -1.342312            0.0   \n",
      "3         0.0       0.0       1.0           0.0  1.476543            0.0   \n",
      "\n",
      "   City_Paris  City_Unknown  \n",
      "0         0.0           0.0  \n",
      "1         1.0           0.0  \n",
      "2         0.0           1.0  \n",
      "3         0.0           1.0  \n"
     ]
    }
   ],
   "source": [
    "# Use TableVectorizer to transform categorical columns\n",
    "vectorizer = TableVectorizer()\n",
    "df_transformed = vectorizer.fit_transform(df)\n",
    "\n",
    "print(\"\\nTransformed Data (Categorical Encoded):\")\n",
    "print(df_transformed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15dc908-1b0c-486e-8d22-f45c1a1322c1",
   "metadata": {},
   "source": [
    "The code uses TableVectorizer to change text data (like 'City' and 'Gender') into numbers. It creates new columns for each category, with 1 or 0 to show if that category is present. This helps turn the data into a form that computers can understand for analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8d944a-7f04-4a94-b1e7-959efdf246c9",
   "metadata": {},
   "source": [
    "**4.MERGING SIMILAR TEXT DATA**\n",
    "\n",
    "If we have a messy text (for example \"NewYork\" vs \"New Yor\"), Skrub will match and merge them as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55ff3cc7-ca63-488a-bc88-802ddacad7b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fuzzy Matched Data:\n",
      "         Name Name__skrub_d4fa04a9__  Purchase\n",
      "0   John Doe                Jon Doe       100\n",
      "1   Alice W.                 Alice        150\n",
      "2  Eve Smith                 Eve s.       200\n"
     ]
    }
   ],
   "source": [
    "from skrub import fuzzy_join\n",
    "import pandas as pd\n",
    "\n",
    "# Sample data: Customer names with typos\n",
    "df1 = pd.DataFrame({'Name': ['John Doe', 'Alice W.', 'Eve Smith']})\n",
    "df2 = pd.DataFrame({'Name': ['Jon Doe', 'Eve s.','Alice '], 'Purchase': [100, 200, 150]})\n",
    "\n",
    "# Use Skrub to match similar names\n",
    "merged_df = fuzzy_join(df1, df2, on='Name')\n",
    "\n",
    "print(\"\\nFuzzy Matched Data:\\n\", merged_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589c52ce-8067-4b5a-b5ee-4f6dd47eb501",
   "metadata": {},
   "source": [
    "The “fuzzy join” recipe is dedicated to joins between two datasets when join keys don’t match exactly.\n",
    "\n",
    "It works by calculating a distance chosen by user and then comparing it to a threshold. DSS handles inner, left, right or outer joins."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f01fe17-7b7f-4777-bdca-4571996658f5",
   "metadata": {},
   "source": [
    "**5.DETECTION AND FILTERING OUTLIERS**\n",
    "\n",
    "There are 4 ways to detect outliers:\n",
    "\n",
    "1.Sorting method\n",
    "\n",
    "2.Data visualization method\n",
    "\n",
    "3.Statistical tests (z scores)\n",
    "\n",
    "4.Interquartile range method\n",
    "\n",
    "To understand in detail we can use the Interquartile Range (IQR) method.\n",
    "\n",
    "first of all lets analyse the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9980b9b2-36b1-4707-aae0-32e169525177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data:\n",
      "   Salary\n",
      "0   30000\n",
      "1   50000\n",
      "2   70000\n",
      "3  999000\n",
      "\n",
      "Cleaned Data (Outliers Removed):\n",
      "   Salary\n",
      "0   30000\n",
      "1   50000\n",
      "2   70000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from skrub import TableVectorizer\n",
    "\n",
    "# Sample data with an outlier\n",
    "data = {'Salary': [30000, 50000, 70000, 999000]}  \n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Detect and remove outliers using IQR method\n",
    "Q1 = df['Salary'].quantile(0.25)\n",
    "Q3 = df['Salary'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Define the lower and upper bounds\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Remove outliers\n",
    "df_cleaned = df[(df['Salary'] >= lower_bound) & (df['Salary'] <= upper_bound)]\n",
    "\n",
    "print(\"Original Data:\")\n",
    "print(df)\n",
    "\n",
    "print(\"\\nCleaned Data (Outliers Removed):\")\n",
    "print(df_cleaned)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ad8010-3c79-46cb-babc-fcf19fc41f9f",
   "metadata": {},
   "source": [
    "The interquartile range (IQR) tells you the range of the middle half of your dataset. \n",
    "You can use the IQR to create “fences” around your data and then define outliers as any values that fall outside those fences.\n",
    "\n",
    "This method is helpful if you have a few values on the extreme ends of your dataset.\n",
    "\n",
    "Interquartile range method\n",
    "\n",
    "Sort your data from low to high\n",
    "\n",
    "Identify the first quartile (Q1), the median, and the third quartile (Q3).\n",
    "\n",
    "Calculate your IQR = Q3 – Q1\n",
    "\n",
    "Calculate your upper fence = Q3 + (1.5 * IQR)\n",
    "\n",
    "Calculate your lower fence = Q1 – (1.5 * IQR)\n",
    "\n",
    "Use your fences to highlight any outliers, all values that fall outside your fences.\n",
    "\n",
    "Your outliers are any values greater than your upper fence or less than your lower fence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5fb4fc5-4bd1-42d2-a5f9-b0fc264ff766",
   "metadata": {},
   "source": [
    "**CONCLUSION:**\n",
    "In the end, skrub has many uses in handling data in python.it helps in simplifying messy data along with organizing it.it helps the users in\n",
    "cleaning the data efficiently with minimum effort. This saves a lot of time along with preserving of accuracy and consistancy.Without tools like Skrub, cleaning large datasets manually can be slow and has higher probality of getting errors.\n",
    "Skrub helps with tasks like filling missing values, fixing inconsistencies, and standardizing formats."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb500f1a-adba-4f5e-8099-f8199fc2091e",
   "metadata": {},
   "source": [
    "**REFERENCES:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2f9d41-a2c7-4bb2-83dc-930c69d69f6f",
   "metadata": {},
   "source": [
    "https://blog.stackademic.com/unleashing-the-power-of-skrub-revolutionizing-table-preparation-for-machine-learning-cdfe9dee8804\n",
    "\n",
    "https://doc.dataiku.com/dss/latest/other_recipes/fuzzy-join.html\n",
    "\n",
    "https://www.scribbr.com/statistics/outliers/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db164dd-d711-46d6-a65a-2e2f47ab2f4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
